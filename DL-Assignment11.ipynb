{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtLawj2KSpPD"
      },
      "source": [
        "### Group Members:\n",
        "\n",
        "- Giovanni Sergio Armido Parri, 16-144-919"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DqURBjymTWgn"
      },
      "source": [
        "# Assignment 11: Adversarial Training\n",
        "\n",
        "In this assignment, we will show that adversarial training provides stability against adversarial attacks for the MNIST dataset.\n",
        "We will compare three different types of training procedures:\n",
        "\n",
        "1. Train with only the original samples\n",
        "2. Train with original samples and samples with added random noise\n",
        "3. Train with original samples and adversarial samples generated by Fast Gradient Sign (FGS) method\n",
        "\n",
        "Note that the results of this experiment might not translate well to other datasets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XVipCIreMn0"
      },
      "source": [
        "## Dataset and Model\n",
        "\n",
        "For our experiments, we come back to the dataset and the model that we have used before.\n",
        "Particularly, we train and test our methods on the MNIST dataset, using a very similar deep network structure as in previous exercises."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GG1Gn-cjeJ1L"
      },
      "source": [
        "### Task 1: Dataset\n",
        "\n",
        "Instantiate the training and validation set splits of MNIST, including data loaders. Select appropriate batch sizes for training and validation sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KIrKxEfESpPF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from tqdm import tqdm\n",
        "\n",
        "# training set and data loader\n",
        "train_set = torchvision.datasets.MNIST(root= './data', train = True, download= True, transform= torchvision.transforms.ToTensor())\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size= 256, shuffle= True)\n",
        "\n",
        "# validation set and data loader\n",
        "validation_set =  torchvision.datasets.MNIST(root= './data', train = False, download= True, transform= torchvision.transforms.ToTensor())\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size= 64, shuffle= True)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tjjy0BcUSpPF"
      },
      "source": [
        "### Task 2: Classification Network\n",
        "\n",
        "Use a similar small-scale network as we have done in Assignment 8.\n",
        "\n",
        "Implement a network with two convolutional and two fully-connected layers.\n",
        "The first convolutional layer has kernel size $7 \\times 7$, stride $=1$, and padding $=0$. The second one has kernel size $5\\times5$, stride $=1$, and padding $=2$. Both are followed by a $2\\times2$ maximum pooling and a ReLU activation.\n",
        "\n",
        "Select appropriate numbers of input and output channels for the convolutions.\n",
        "The first fully-connected layer reduces the feature map to a certain size $K$, which can be selected freely, while the second layer produces $O=10$ logits.\n",
        "\n",
        "Note:\n",
        "\n",
        "* You can also build your network with `torch.nn.Sequential`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kvt01gtNSpPG"
      },
      "outputs": [],
      "source": [
        "class Network (torch.nn.Module):\n",
        "  def __init__(self, Q1, Q2, K, O):\n",
        "    # call base class constrcutor\n",
        "    super(Network,self).__init__()\n",
        "    self.conv1 = torch.nn.Conv2d(in_channels=1, out_channels=Q1, kernel_size=7, stride=1, padding=0)\n",
        "    self.conv2 = torch.nn.Conv2d(in_channels=Q1, out_channels=Q2, kernel_size=5, stride=1, padding=2)\n",
        "    self.fc1 = torch.nn.Linear(in_features=Q2*5*5, out_features=K)\n",
        "    self.fc2 = torch.nn.Linear(in_features=K, out_features=O)\n",
        "    self.maxpool = torch.nn.MaxPool2d(kernel_size=2, stride = 2)\n",
        "    self.flatten = torch.nn.Flatten()\n",
        "    self.activation = torch.nn.ReLU()\n",
        "\n",
        "  def forward(self,x):                        \n",
        "    x = self.conv1(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.maxpool(x)\n",
        "    x = self.activation(x)\n",
        "    x = self.fc1(self.flatten(x))\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYuugExweTA8"
      },
      "source": [
        "## Image Manipulation\n",
        "\n",
        "We implement three different ways to manipulate the images for generating additional training data.\n",
        "The first way is to compute adversarial samples using the Fast Gradient Sign method.\n",
        "Here, we want to adapt the image such that we maximize the loss between the network output and the target.\n",
        "For this purpose, we need to compute the FGS adversarial samples by using the derivative of the loss with respect to the image:\n",
        "\n",
        "$$\\mathbf X_{\\mathrm{FGS}} = \\mathbf X + \\alpha \\mathrm{sign}(\\nabla_{\\mathbf X})$$\n",
        "\n",
        "with\n",
        "\n",
        "$$\\nabla_{\\mathbf X} = \\frac{\\partial \\mathcal J_{CCE}}{\\partial \\mathbf X} $$\n",
        "\n",
        "Then we need to implement the Fast Gradient Value method,\n",
        "\n",
        "$$\\mathbf X_{\\mathrm{FGV}} = \\mathbf X + \\alpha \\frac{\\nabla_{\\mathbf X}} {\\mathrm{max} |\\nabla_{\\mathbf X}|}$$\n",
        "\n",
        "and the generated adversarial samples will only be used in the validation, not training, to check whether the network trained with FGS is also robust to FGV samples.\n",
        "\n",
        "The third type of manipulation is to add simple noise that represents the same type and magnitude of manipulations as FGS, i.e., we want our noisy image to be:\n",
        "\n",
        "$$\\mathbf X_{\\mathrm{noise}} = \\mathbf X + \\alpha \\{-1,1\\}^{D\\times E}$$\n",
        "\n",
        "where $D$ and $E$ are the width and the height of the original image. $-1$ and $1$ are sampled with the same probability, and independently for each pixel. In all three methods, $\\alpha$ controls the magnitude of the added part.\n",
        "\n",
        "In order to represent actual images, we will restrict the pixel values of both $\\mathbf X_{\\mathrm{FGS}}$, $\\mathbf X_{\\mathrm{FGV}}$, and $\\mathbf X_{\\mathrm{noise}}$ to be in the range $[0,1]$ by clipping any value that is outside that range.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07stUk92SpPG"
      },
      "source": [
        "### Task 3: Fast Gradient Sign\n",
        "\n",
        "Implement a function that computes the gradient of the given loss function w.r.t. the input.\n",
        "Compute the adversarial sample using the above definition of $\\mathbf X_{\\mathrm{FGS}}$, and restrict the output values to be in the range $[0,1]$.\n",
        "\n",
        "Note that this function will be used with batches of samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T0DrI7avSpPG"
      },
      "outputs": [],
      "source": [
        "def FGS(x, t, network, loss, alpha=0.3):\n",
        "  # tell autograd that we need the gradient for the input\n",
        "  x.requires_grad_(True)\n",
        "  # forward input\n",
        "  z = network(x)\n",
        "  # compute loss and gradient\n",
        "  J = loss(z, t)\n",
        "  network.zero_grad()\n",
        "  # get the gradient\n",
        "  J.backward()\n",
        "  gradient = x.grad.data\n",
        "  # create FGS adversarial sample\n",
        "  adversarial_sample = x + alpha*gradient.sign()\n",
        "\n",
        "  return torch.clamp(adversarial_sample, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utavZrLF776e"
      },
      "source": [
        "### Task 4: Fast Gradient Value\n",
        "\n",
        "Implement a function that computes the gradient of the given loss function w.r.t. the input.\n",
        "Compute the adversarial sample using the above definition of $\\mathbf X_{\\mathrm{FGV}}$, and restrict the output values to be in the range $[0,1]$.\n",
        "\n",
        "Note that this function will be used with batches of samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFhXvdOP8A0p"
      },
      "outputs": [],
      "source": [
        "def FGV(x, t, network, loss, alpha=0.6):\n",
        "  # tell autograd that we need the gradient for the input\n",
        "  x.requires_grad_(True)\n",
        "  # forward input\n",
        "  z = network(x)\n",
        "  # compute loss and gradient\n",
        "  J = loss(z, t)\n",
        "  network.zero_grad()\n",
        "  J.backward()\n",
        "  # get the gradient\n",
        "  gradient = x.grad.data\n",
        "  # create FGV adversarial sample\n",
        "  adversarial_sample = x + alpha * gradient/(torch.amax(torch.abs(gradient), dim=[1,2,3], keepdim=True) + 1e-10)\n",
        "  \n",
        "  return torch.clamp(adversarial_sample, 0, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJzhaUraSpPG"
      },
      "source": [
        "### Task 5: Random Noise\n",
        "\n",
        "Implement a function that computes the noisy sample according to the definition of $\\mathbf X_{\\mathrm{noise}}$ shown above, and restricts the output values to be in the range $[0,1]$.\n",
        "\n",
        "\n",
        "Note that this function will also be used with batches of samples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_DefcwdSpPH"
      },
      "outputs": [],
      "source": [
        "def noise(x, alpha=0.3):\n",
        "  # generate noise\n",
        "  choices = torch.tensor([-1, 1])\n",
        "\n",
        "  noise = choices[torch.randint(2, x.shape)]\n",
        "  noise = noise.to(device)\n",
        "\n",
        "  # Add noise and clamp\n",
        "  noisy_sample = x + alpha * noise\n",
        "  return noisy_sample.data.clamp_(0,1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qhe2hLl_8FrI"
      },
      "source": [
        "### Test 1: Adversarial Samples and Noisy Samples\n",
        "\n",
        "Verify that the generated $\\mathbf X_{\\mathrm{FGS}}$, $\\mathbf X_{\\mathrm{FGV}}$, and $\\mathbf X_{\\mathrm{noise}}$ have the same shape as $\\mathbf X$ and all pixels are ranged in $[0,1]$.\n",
        "\n",
        "Visualize $\\mathbf X$, $\\mathbf X_{\\mathrm{FGS}}$, $\\mathbf X_{\\mathrm{FGV}}$, and $\\mathbf X_{\\mathrm{noise}}$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4QxSNu88JnW"
      },
      "outputs": [],
      "source": [
        "# create network\n",
        "network = Network(32,64,10,10).to(device)\n",
        "\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# use first validation batch\n",
        "x, t = next(iter(validation_loader))\n",
        "\n",
        "# Check the noisy samples: correct shape and range\n",
        "x_noise = noise(x.to(device), alpha=0.3)\n",
        "assert x_noise.shape == x.shape\n",
        "assert torch.all(x_noise >= 0) and torch.all(x_noise <= 1)\n",
        "\n",
        "# Check the generated adversarial samples: correct shape and range\n",
        "x_fgs = FGS(x.to(device), t.to(device), network, loss, alpha=0.3)\n",
        "assert x_fgs.shape == x.shape\n",
        "assert torch.all(x_fgs >= 0) and torch.all(x_fgs <= 1)\n",
        "\n",
        "x_fgv = FGV(x.to(device), t.to(device), network, loss, alpha=0.6)\n",
        "assert x_fgv.shape == x.shape\n",
        "assert torch.all(x_fgv >= 0) and torch.all(x_fgv <= 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "iXbFZKD1Kq64",
        "outputId": "8c3f3f1b-6fff-4a42-81fe-e836bf7d7a5b"
      },
      "outputs": [],
      "source": [
        "samples = [x.cpu().detach().numpy(), x_fgs.cpu().detach().numpy(), x_fgv.cpu().detach().numpy(), x_noise.cpu().detach().numpy()]\n",
        "\n",
        "# plot images\n",
        "from matplotlib import pyplot\n",
        "pyplot.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "fig, axes = pyplot.subplots(nrows=4, ncols=10, figsize=(15, 6))\n",
        "\n",
        "for i in range(4):\n",
        "    for j in range(10):\n",
        "      axes[i][j].imshow(samples[i][j].squeeze())\n",
        "      axes[i][j].axis(\"off\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P9elqkk-eZlA"
      },
      "source": [
        "## Training and Evaluation\n",
        "\n",
        "We will implement three different variations of the training procedure, which will be combined into one function.\n",
        "In all three variations, we will iterate over all batches in the training set and train the network with standard categorical cross-entropy loss.\n",
        "Variation 1 will only perform the **standard training**.\n",
        "Variation 2 will generate **FGS adversarial samples** for all images in the batch, and **train with the adversarial samples** while assigning the original targets.\n",
        "In variation 3, we will also train with additional data, but instead of generating adversarial samples, we will just **add noise** to our images.\n",
        "\n",
        "For evaluation, we will compute three different measures.\n",
        "First, we compute the **classification accuracy** of the network on the clean, unperturbed images of the validation set.\n",
        "Second, we will create adversarial samples via our FGS technique for **all correctly classified validation set samples** and assess how many of these **adversarial samples are classified as their original class** by the network.\n",
        "Then, we will repeat the same procedure for **FGV adversarial samples**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhJJQpLVSpPH"
      },
      "source": [
        "### Task 6: Training Loop\n",
        "\n",
        "For a given network, loss and optimizer, implement a function that trains the network for one epoch on the training data.\n",
        "If desired by the `add_additional_samples` parameter, implement variation 1, 2, or 3.\n",
        "Perform update steps where they fit.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4VZZ96t_SpPH"
      },
      "outputs": [],
      "source": [
        "def training_loop(network, loss, optimizer, add_additional_samples = None, alpha=0.3):\n",
        "  for x,t in tqdm(train_loader):\n",
        "    # compute output for current batch\n",
        "    x = x.to(device)\n",
        "    t = t.to(device)\n",
        "    network.train()\n",
        "    z = network(x)\n",
        "    # compute loss\n",
        "    J = loss(z, t)\n",
        "    # compute gradient\n",
        "    optimizer.zero_grad()\n",
        "    J.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if add_additional_samples is not None:\n",
        "      # compute modified samples for batch\n",
        "      if add_additional_samples == \"FGS\":\n",
        "        # create FGS adversarial samples\n",
        "        x_hat = FGS(x, t, network, loss, alpha)\n",
        "      else:\n",
        "        # create noisy samples\n",
        "        x_hat = noise(x, alpha)\n",
        "      # compute output for modified samples\n",
        "      z_hat = network(x_hat)\n",
        "      # compute loss on modified samples\n",
        "      J = loss(z_hat, t)\n",
        "      # compute gradient\n",
        "      optimizer.zero_grad()\n",
        "      J.backward()\n",
        "      optimizer.step()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkjEj9h6SpPH"
      },
      "source": [
        "### Task 7: Validation Loop\n",
        "\n",
        "\n",
        "For a given network and loss function, iterate over the validation set and compute the classification accuracy on the original validation set samples.\n",
        "\n",
        "For each batch, select the correctly classified images. For these, generate two types of adversarial samples, using FGS and FGV defined above, respectively.\n",
        "\n",
        "Finally, compute how many of the adversarial samples are still classified as the original class by the network.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "69LkKk9hSpPH"
      },
      "outputs": [],
      "source": [
        "def validation_loop(network, loss, alpha_fgs=0.3, alpha_fgv=0.7):\n",
        "  total, correct_clean_count, correct_fgs_count, correct_fgv_count = 0,0,0,0\n",
        "  total_c = 0\n",
        "  # iterate over validation set samples\n",
        "  for x,t in tqdm(validation_loader):\n",
        "    x = x.to(device)\n",
        "    t = t.to(device)\n",
        "    network.eval()\n",
        "    with torch.no_grad():\n",
        "      # classify original samples\n",
        "      z = network(x)\n",
        "      # compute classification accuracy on original samples\n",
        "      correct_clean_count += torch.sum(torch.argmax(z, dim=1) == t).item()\n",
        "      total += len(t)\n",
        "\n",
        "    # select the correctly classified samples\n",
        "    x_correct = x[torch.argmax(z, dim=1) == t]\n",
        "    t_correct = t[torch.argmax(z, dim=1) == t]\n",
        "    # create adversarial samples using FGS and FGV\n",
        "    x_attack_fgs = FGS(x_correct, t_correct, network, loss, alpha_fgs)\n",
        "    x_attack_fgv = FGV(x_correct, t_correct, network, loss, alpha_fgv)\n",
        "\n",
        "      # check how many are correctly classified\n",
        "    with torch.no_grad():\n",
        "      # classify adversarial samples\n",
        "      z_attack_fgs = network(x_attack_fgs)\n",
        "      z_attack_fgv = network(x_attack_fgv)\n",
        "\n",
        "      # compute classification accuracy on adversarial samples\n",
        "      correct_fgs_count += torch.sum(torch.argmax(z_attack_fgs, dim=1) == t_correct).item()\n",
        "      correct_fgv_count += torch.sum(torch.argmax(z_attack_fgv, dim=1) == t_correct).item()\n",
        "      total_c += len(t_correct)\n",
        "  # compute clean and adversarial accuracies and return them\n",
        "  clean_accuracy = correct_clean_count / total\n",
        "  fgs_accuracy = correct_fgs_count / total_c\n",
        "  fgv_accuracy = correct_fgv_count / total_c\n",
        "  return clean_accuracy, fgs_accuracy, fgv_accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hou2QDRYSpPI"
      },
      "source": [
        "### Task 8: Training of Three Networks\n",
        "\n",
        "Instantiate three networks, one to train with only clean samples, one to additionally train with FGS adversarial samples, and one to additionally train with noise.\n",
        "\n",
        "Instantiate corresponding optimizers that train these networks. Make use of SGD with an appropriate learning rate $\\eta$ and categorical cross-entropy loss.\n",
        "\n",
        "Train each of the three networks for 10 epochs (or more) using their specific data extension.\n",
        "\n",
        "Compute and store the validation set accuracy on the clean, FGS adversarial samples, and FGV adversarial samples -- note that adversarial samples will be generated for each network separately -- after each training epoch. So the training time is extended as compared to normal training since the creation of adversarial samples requires time.\n",
        "\n",
        "Remember to setup a higher $\\alpha$ when generating FGV samples (at least $\\times 2$ to the FGS $\\alpha$)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RiwGRufOSpPI",
        "outputId": "44d6bf88-a21e-4858-9d73-9b74fe68fc37"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# define one network for each training procedure\n",
        "networks = [Network(32,64,10,10).to(device) for _ in range(3)]\n",
        "# define optimizer\n",
        "optimizer = [torch.optim.SGD(networks[i].parameters(), lr=0.001) for i in range(3)]\n",
        "\n",
        "\n",
        "# define loss function\n",
        "loss = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# store accuracies on clean and adversarial samples for the three cases\n",
        "clean_accuracies = []\n",
        "fgs_accuracies = []\n",
        "fgv_accuracies = []\n",
        "\n",
        "# iterate over 10 epochs (or more)\n",
        "for epoch in range(3):\n",
        "  # perform training loop\n",
        "  for i in range(3):\n",
        "    training_loop(networks[i], loss, optimizer[i], add_additional_samples=[None, \"FGS\", \"Noise\"][i], alpha=0.3)\n",
        "  # compute and store validation set accuracies\n",
        "  clean_accuracies.append(validation_loop(networks[0], loss))\n",
        "  fgs_accuracies.append(validation_loop(networks[1], loss))\n",
        "  fgv_accuracies.append(validation_loop(networks[2], loss))\n",
        "  print(f\"epochs {epoch+1}/{10}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvU_YqfHSpPI"
      },
      "source": [
        "### Task 9: Plotting of Accuracies\n",
        "\n",
        "Generate three plots.\n",
        "\n",
        "In the first plot, compare the accuracies on the clean images of the validation set over the 10 epochs. (Plot clean accuracies)\n",
        "\n",
        "In the second plot, compare the stability of the networks w.r.t. FGS adversarial samples, i.e., how many FGS adversarial samples can change the classification of the network. (Plot FGS adversarial accuracies)\n",
        "\n",
        "In the third plot, compare the stability of the networks w.r.t. FGV adversarial samples, i.e., how many FGV adversarial samples can change the classification of the network. (Plot FGV adversarial accuracies)\n",
        "\n",
        "Exemplary plots can be found in the slides.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "ZhPOZLLXSpPI",
        "outputId": "f953c3bb-fec1-43ce-bf93-bfa200a0824b"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot\n",
        "import numpy as np\n",
        "\n",
        "clean_accuracies = np.array(clean_accuracies)\n",
        "fgs_accuracies = np.array(fgs_accuracies)\n",
        "fgv_accuracies = np.array(fgv_accuracies)\n",
        "\n",
        "print(clean_accuracies)\n",
        "pyplot.figure(figsize=(18,6))\n",
        "# plot clean accuracies\n",
        "pyplot.subplot(131)\n",
        "pyplot.plot(clean_accuracies[:,0], label=\"Default Training\")\n",
        "pyplot.plot(clean_accuracies[:,1], label=\"Training with FGS\")\n",
        "pyplot.plot(clean_accuracies[:,2], label=\"Training with Noise\")\n",
        "pyplot.legend()\n",
        "\n",
        "# plot FGS adversarial accuracies\n",
        "pyplot.subplot(132)\n",
        "pyplot.plot(fgs_accuracies[:,0], label=\"Default Training\")\n",
        "pyplot.plot(fgs_accuracies[:,1], label=\"Training with FGS\")\n",
        "pyplot.plot(fgs_accuracies[:,2], label=\"Training with Noise\")\n",
        "pyplot.legend()\n",
        "# plot FGV adversarial accuracies\n",
        "pyplot.subplot(133)\n",
        "pyplot.plot(fgv_accuracies[:,0], label=\"Default Training\")\n",
        "pyplot.plot(fgv_accuracies[:,1], label=\"Training with FGS\")\n",
        "pyplot.plot(fgv_accuracies[:,2], label=\"Training with Noise\")\n",
        "\n",
        "pyplot.legend()\n",
        "\n",
        "pyplot.tight_layout()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BLED6rhlTWgr"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "interpreter": {
      "hash": "a29cabff5744fce69e08a959ab87b9e77a9f67b498d08783caa8c3bb16f23a00"
    },
    "kernelspec": {
      "display_name": "Python 3.8.10 ('DL')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
